{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1551NXfDLdOsohjKKza4mJujd5_JXVFfe","timestamp":1674526695145}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"wmCbxoDrADcF"},"source":["# Google Colab setup with Google Drive folder\n","\n","This notebook provides the code you need to set up Google Colab to run and import files from within a Google Drive folder.\n","\n","This will allow you to upload assignment code to your Google Drive and then run the code on Google Colab machines (with free GPUs if needed). \n","\n","You will need to create a folder in your Google Drive to hold your assignments and you will need to open Colaboratory within this folder before running the set up code (check the link above to see how)."]},{"cell_type":"markdown","metadata":{"id":"zWhrmhqVCyGH"},"source":["# Mount Google Drive\n","\n","This will allow the Colab machine to access Google Drive folders by mounting the drive on the machine. You will be asked to copy and paste an authentication code."]},{"cell_type":"code","metadata":{"id":"Wv2oKmF9AJtI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231970555,"user_tz":480,"elapsed":16274,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"66168323-b772-4e8a-a6ac-93d715fcd30c"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","metadata":{"id":"kKGxaMcmP_Et","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231970556,"user_tz":480,"elapsed":6,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"435a64fc-13d3-4b84-8ab1-1dd1778bfb47"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"markdown","metadata":{"id":"4Qs04PPwDOFy"},"source":["# Change directory to allow imports\n","\n","\n","As noted above, you should create a Google Drive folder to hold all your assignment files. You will need to add this code to the top of any python notebook you run to be able to import python files from your drive assignment folder (you should change the file path below to be your own assignment folder). Following the hand-out, you should have a directory \"SFU_CMPT_CV_lab2\" on g-drive, which should have a directory \"data\", which contains three tar.gz files."]},{"cell_type":"code","metadata":{"id":"UA2-UyfpEc9O"},"source":["import os\n","os.chdir(\"/content/gdrive/My Drive/SFU_CMPT_CV_lab2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyRCWAIyRHWc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231971898,"user_tz":480,"elapsed":1345,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"c294e627-8f53-4a3d-f5d0-3fdcd3d51d67"},"source":["ls # Check if this is your folder"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/  plot.png  submission_netid.csv\n"]}]},{"cell_type":"markdown","metadata":{"id":"SJOCaUMilRz_"},"source":["# Copy data to local dir"]},{"cell_type":"code","metadata":{"id":"90MxG_eRla0W"},"source":["!mkdir /data\n","!cp data/cifar100.tar.gz /data/\n","!tar -xf /data/cifar100.tar.gz -C /data/\n","!cp data/test.tar.gz /data\n","!tar -xf /data/test.tar.gz -C /data\n","!cp data/train.tar.gz /data\n","!tar -xf /data/train.tar.gz -C /data/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvFEFItpl98p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231986865,"user_tz":480,"elapsed":9,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"5bd99c82-f857-4277-a245-1c2349c448aa"},"source":["ls /data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcifar100\u001b[0m/  cifar100.tar.gz  \u001b[01;34mtest\u001b[0m/  test.tar.gz  \u001b[01;34mtrain\u001b[0m/  train.tar.gz\n"]}]},{"cell_type":"markdown","metadata":{"id":"DDU5aVgR9QBx"},"source":["# Set up GPU and PyTorch\n","\n","First, ensure that your notebook on Colaboratory is set up to use GPU. After opening the notebook on Colaboratory, go to Edit>Notebook settings, select Python 3 under \"Runtime type,\" select GPU under \"Hardware accelerator,\" and save.\n","\n","Next, install PyTorch:"]},{"cell_type":"code","metadata":{"id":"kjbQtzKT9Uc2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231990208,"user_tz":480,"elapsed":3347,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"7c69e2bf-f3cc-4896-ca0b-cf7d3bd0ae8c"},"source":["!pip3 install torch torchvision"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"u_BekZYY9Vzx"},"source":["Make sure that pytorch is installed and works with GPU:"]},{"cell_type":"code","metadata":{"id":"8TXSJWQa9efx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231998052,"user_tz":480,"elapsed":7849,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"2e857f00-e48f-4565-a911-87e071d2dcf9"},"source":["import torch\n","a = torch.Tensor([1]).cuda()\n","print(a)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.], device='cuda:0')\n"]}]},{"cell_type":"code","metadata":{"id":"OEeRNsCjRXZK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231998052,"user_tz":480,"elapsed":6,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"29a45cd1-81d3-4d48-d23e-45f8a0e82aa5"},"source":["torch.cuda.is_available()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"qChgLJERsvZP"},"source":["# Part 1"]},{"cell_type":"code","metadata":{"id":"IlyCnvf6WzjR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231998414,"user_tz":480,"elapsed":364,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"a2c7aacf-2cc6-4238-8a16-f15f8a6f4256"},"source":["\"\"\"Headers\"\"\"\n","\n","from __future__ import print_function\n","from PIL import Image\n","import os\n","import os.path\n","import numpy as np\n","import sys\n","if sys.version_info[0] == 2:\n","    import cPickle as pickle\n","else:\n","    import pickle\n","\n","import torch.utils.data as data\n","from torchvision.datasets.utils import download_url, check_integrity\n","\n","import csv\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os.path\n","import sys\n","import torch\n","import torch.utils.data\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","np.random.seed(111)\n","torch.cuda.manual_seed_all(111)\n","torch.manual_seed(111)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f8fd2aac2d0>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"137GhZMrcTuj"},"source":["\n","\n","## **Just execute the cell below. This is the dataloader. DO NOT CHANGE ANYTHING IN HERE!**\n"]},{"cell_type":"code","metadata":{"id":"URUH4fzzWqKr"},"source":["\"\"\"\"\"\"\n","\n","class CIFAR10_SFU_CV(data.Dataset):\n","    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n","\n","    Args:\n","        root (string): Root directory of dataset where directory\n","            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n","        train (bool, optional): If True, creates dataset from training set, otherwise\n","            creates from test set.\n","        transform (callable, optional): A function/transform that  takes in an PIL image\n","            and returns a transformed version. E.g, ``transforms.RandomCrop``\n","        target_transform (callable, optional): A function/transform that takes in the\n","            target and transforms it.\n","        download (bool, optional): If true, downloads the dataset from the internet and\n","            puts it in root directory. If dataset is already downloaded, it is not\n","            downloaded again.\n","\n","    \"\"\"\n","    base_folder = 'cifar100'\n","    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n","    filename = \"cifar100.tar.gz\"\n","    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n","    train_list = [\n","        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n","        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n","        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n","        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n","        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n","    ]\n","\n","    test_list = [\n","        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n","    ]\n","\n","    def __init__(self, root, fold=\"train\",\n","                 transform=None, target_transform=None,\n","                 download=False):\n","        \n","        fold = fold.lower()\n","\n","        self.train = False\n","        self.test = False\n","        self.val = False\n","\n","        if fold == \"train\":\n","            self.train = True\n","        elif fold == \"test\":\n","            self.test = True\n","        elif fold == \"val\":\n","            self.val = True\n","        else:\n","            raise RuntimeError(\"Not train-val-test\")\n","\n","\n","        self.root = os.path.expanduser(root)\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","        fpath = os.path.join(root, self.filename)\n","        if not self._check_integrity():\n","            raise RuntimeError('Dataset not found or corrupted.' +\n","                               ' Download it and extract the file again.')\n","\n","        # now load the picked numpy arrays\n","        if self.train or self.val:\n","            self.train_data = []\n","            self.train_labels = []\n","            for fentry in self.train_list:\n","                f = fentry[0]\n","                file = os.path.join(self.root, self.base_folder, f)\n","                fo = open(file, 'rb')\n","                if sys.version_info[0] == 2:\n","                    entry = pickle.load(fo)\n","                else:\n","                    entry = pickle.load(fo, encoding='latin1')\n","                self.train_data.append(entry['data'])\n","                if 'labels' in entry:\n","                    self.train_labels += entry['labels']\n","                else:\n","                    self.train_labels += entry['fine_labels']\n","                fo.close()\n","\n","            self.train_data = np.concatenate(self.train_data)\n","            self.train_data = self.train_data.reshape((50000, 3, 32, 32))\n","            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n","            \n","            p = np.arange(0,50000,10)\n","            mask_train = np.ones((50000,), dtype=bool)\n","            mask_train[p] = False\n","            mask_val = np.zeros((50000,), dtype=bool)\n","            mask_val[p] = True\n","\n","            copy_all_data = np.array(self.train_data)\n","            self.val_data = np.array(copy_all_data[mask_val])\n","            self.train_data = np.array(copy_all_data[mask_train])\n","            \n","            copy_all_labels = np.array(self.train_labels)\n","            self.val_labels = np.array(copy_all_labels[mask_val])\n","            self.train_labels = np.array(copy_all_labels[mask_train])\n","\n","        elif self.test:\n","            f = self.test_list[0][0]\n","            file = os.path.join(self.root, self.base_folder, f)\n","            fo = open(file, 'rb')\n","            if sys.version_info[0] == 2:\n","                entry = pickle.load(fo)\n","            else:\n","                entry = pickle.load(fo, encoding='latin1')\n","            self.test_data = entry['data']\n","\n","            if 'labels' in entry:\n","                self.test_labels = entry['labels']\n","            else:\n","                self.test_labels = entry['fine_labels']\n","            fo.close()\n","            self.test_data = self.test_data.reshape((10000, 3, 32, 32))\n","            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Args:\n","            index (int): Index\n","\n","        Returns:\n","            tuple: (image, target) where target is index of the target class.\n","        \"\"\"\n","        if self.train:\n","            img, target = self.train_data[index], self.train_labels[index]\n","        elif self.test:\n","            img, target = self.test_data[index], self.test_labels[index]\n","        elif self.val:\n","            img, target = self.val_data[index], self.val_labels[index]\n","\n","        # doing this so that it is consistent with all other datasets\n","        # to return a PIL Image\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        if self.train:\n","            return len(self.train_data)\n","        elif self.test:\n","            return len(self.test_data)\n","        elif self.val:\n","            return len(self.val_data)\n","\n","    def _check_integrity(self):\n","        root = self.root\n","        for fentry in (self.train_list + self.test_list):\n","            filename, md5 = fentry[0], fentry[1]\n","            fpath = os.path.join(root, self.base_folder, filename)\n","            if not check_integrity(fpath, md5):\n","                return False\n","        return True\n","\n","    def __repr__(self):\n","        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n","        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n","        tmp = 'train' if self.train is True else 'test'\n","        fmt_str += '    Split: {}\\n'.format(tmp)\n","        fmt_str += '    Root Location: {}\\n'.format(self.root)\n","        tmp = '    Transforms (if any): '\n","        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n","        tmp = '    Target Transforms (if any): '\n","        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n","        return fmt_str\n","\n","\n","class CIFAR100_SFU_CV(CIFAR10_SFU_CV):\n","    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n","\n","    This is a subclass of the `CIFAR10` Dataset.\n","    \"\"\"\n","    base_folder = 'cifar100'\n","    filename = \"cifar100.tar.gz\"\n","    tgz_md5 = 'e68a4c763591787a0b39fe2209371f32'\n","    train_list = [\n","        ['train_cs543', '49eee854445c1e2ebe796cd93c20bb0f'],\n","    ]\n","\n","    test_list = [\n","        ['test_cs543', 'd3fe9f6a9251bd443f428f896d27384f'],\n","    ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JpFMv7HtcII4"},"source":["This file has been adapted from the easy-to-use tutorial released by PyTorch:\n","http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","\n","Training an image classifier\n","----------------------------\n","\n","We will do the following steps in order:\n","\n","1. Load the CIFAR100_SFU_CV training, validation and test datasets using\n","   torchvision. Use torchvision.transforms to apply transforms on the\n","   dataset.\n","2. Define a Convolution Neural Network - BaseNet\n","3. Define a loss function and optimizer\n","4. Train the network on training data and check performance on val set.\n","   Plot train loss and validation accuracies.\n","5. Try the network on test data and create .csv file for submission to kaggle"]},{"cell_type":"code","metadata":{"id":"Ld6juH34dWWq"},"source":["# <<TODO#5>> Based on the val set performance, decide how many\n","# epochs are apt for your model.\n","# ---------\n","EPOCHS = 25\n","# ---------\n","\n","IS_GPU = True\n","TEST_BS = 256\n","TOTAL_CLASSES = 100\n","TRAIN_BS = 32\n","PATH_TO_CIFAR100_SFU_CV = \"/data/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ENlTTMi-qFD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675231999426,"user_tz":480,"elapsed":5,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"2f1be70e-52b2-4f09-dbb3-922b3b35d7ea"},"source":["ls /data/cifar100/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test_cs543  train_cs543\n"]}]},{"cell_type":"code","metadata":{"id":"d57CSAj1dfix"},"source":["def calculate_val_accuracy(valloader, is_gpu):\n","    \"\"\" Util function to calculate val set accuracy,\n","    both overall and per class accuracy\n","    Args:\n","        valloader (torch.utils.data.DataLoader): val set \n","        is_gpu (bool): whether to run on GPU\n","    Returns:\n","        tuple: (overall accuracy, class level accuracy)\n","    \"\"\"    \n","    correct = 0.\n","    total = 0.\n","    predictions = []\n","\n","    class_correct = list(0. for i in range(TOTAL_CLASSES))\n","    class_total = list(0. for i in range(TOTAL_CLASSES))\n","\n","    for data in valloader:\n","        images, labels = data\n","        if is_gpu:\n","            images = images.cuda()\n","            labels = labels.cuda()\n","        outputs = net(Variable(images))\n","        _, predicted = torch.max(outputs.data, 1)\n","        predictions.extend(list(predicted.cpu().numpy()))\n","        total += labels.size(0)\n","        # correct += (predicted == labels).sum()\n","        correct += torch.sum(predicted == labels).detach().cpu().numpy()\n","\n","        # c = (predicted == labels).squeeze()\n","        c = torch.squeeze(predicted == labels).detach().cpu().numpy()\n","        for i in range(len(labels)):\n","            label = labels[i]\n","            class_correct[label] += c[i]\n","            class_total[label] += 1\n","\n","    class_accuracy = 100 * np.divide(class_correct, class_total)\n","    return 100*correct/total, class_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aq2qOUaJeAWJ"},"source":["1.** Loading CIFAR100_SFU_CV**\n","\n","We modify the dataset to create CIFAR100_SFU_CV dataset which consist of 45000 training images (450 of each class), 5000 validation images (50 of each class) and 10000 test images (100 of each class). The train and val datasets have labels while all the labels in the test set are set to 0.\n"]},{"cell_type":"code","metadata":{"id":"C2UcDZmtdfq3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aea51ad7-f72c-4bc1-9d2f-20588af82baf","executionInfo":{"status":"ok","timestamp":1675232006521,"user_tz":480,"elapsed":7096,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}}},"source":["# The output of torchvision datasets are PILImage images of range [0, 1].\n","# Using transforms.ToTensor(), transform them to Tensors of normalized range\n","# [-1, 1].\n","\n","\n","# <<TODO#1>> Use transforms.Normalize() with the right parameters to \n","# make the data well conditioned (zero mean, std dev=1) for improved training.\n","# <<TODO#2>> Try using transforms.RandomCrop() and/or transforms.RandomHorizontalFlip()\n","# to augment training data.\n","# After your edits, make sure that test_transform should have the same data\n","# normalization parameters as train_transform\n","# You shouldn't have any data augmentation in test_transform (val or test data is never augmented).\n","# ---------------------\n","\n","import torchvision.transforms as transforms\n","\n","train_transform = transforms.Compose([\n","     transforms.RandomCrop(32, padding=4,padding_mode='reflect'),\n","     transforms.RandomHorizontalFlip(),\n","     transforms.ToTensor(),\n","    #  transforms.Normalize(mean = [0.5038413,0.48397574,0.4388329], std = [0.26844665,0.25662765,0.27560112]),\n","     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","    ])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean = [0.5038413,0.48397574,0.4388329], std = [0.26844665,0.25662765,0.27560112])\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","    ])\n","\n","trainset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold=\"train\",\n","                                        download=True, transform=train_transform)\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BS,\n","                                          shuffle=True, num_workers=2)\n","print(\"Train set size: \"+str(len(trainset)))\n","\n","valset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold=\"val\",\n","                                       download=True, transform=test_transform)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=TEST_BS,\n","                                         shuffle=False, num_workers=2)\n","print(\"Val set size: \"+str(len(valset)))\n","\n","testset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold=\"test\",\n","                                       download=True, transform=test_transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=TEST_BS,\n","                                         shuffle=False, num_workers=2)\n","print(\"Test set size: \"+str(len(testset)))\n","\n","# The 100 classes for CIFAR100\n","classes = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train set size: 45000\n","Val set size: 5000\n","Test set size: 10000\n"]}]},{"cell_type":"code","source":["########################################################################\n","# 2. Define a Convolution Neural Network\n","# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","# We provide a basic network that you should understand, run and\n","# eventually improve\n","# <<TODO>> Add more conv layers\n","# <<TODO>> Add more fully connected (fc) layers\n","# <<TODO>> Add regularization layers like Batchnorm.\n","#          nn.BatchNorm2d after conv layers:\n","#          http://pytorch.org/docs/master/nn.html#batchnorm2d\n","#          nn.BatchNorm1d after fc layers:\n","#          http://pytorch.org/docs/master/nn.html#batchnorm1d\n","# This is a good resource for developing a CNN for classification:\n","# http://cs231n.github.io/convolutional-networks/#layers\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","def conv_block(in_channels, out_channels, pool=False):\n","    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n","              nn.BatchNorm2d(out_channels), \n","              nn.ReLU(inplace=True)]\n","    if pool: layers.append(nn.MaxPool2d(2))\n","    return nn.Sequential(*layers)\n","\n","class BaseNet(nn.Module):\n","    def __init__(self):\n","        super(BaseNet, self).__init__()\n","        \n","        # <<TODO#3>> Add more conv layers with increasing \n","        # output channels\n","        # <<TODO#4>> Add normalization layers after conv\n","        # layers (nn.BatchNorm2d)\n","\n","        # Also experiment with kernel size in conv2d layers (say 3\n","        # inspired from VGGNet)\n","        # To keep it simple, keep the same kernel size\n","        # (right now set to 5) in all conv layers.\n","        # Do not have a maxpool layer after every conv layer in your\n","        # deeper network as it leads to too much loss of information.\n","\n","        # self.conv1 = nn.Conv2d(3, 6, 5)\n","        # self.pool = nn.MaxPool2d(2, 2)\n","        # self.conv2 = nn.Conv2d(6, 16, 5)\n","\n","        # <<TODO#3>> Add more linear (fc) layers\n","        # <<TODO#4>> Add normalization layers after linear and\n","        # experiment inserting them before or after ReLU (nn.BatchNorm1d)\n","        # More on nn.sequential:\n","        # http://pytorch.org/docs/master/nn.html#torch.nn.Sequential\n","\n","        # self.fc_net = nn.Sequential(\n","        #     nn.Linear(16 * 5 * 5, TOTAL_CLASSES//2),\n","        #     nn.ReLU(inplace=True),\n","        #     nn.Linear(TOTAL_CLASSES//2, TOTAL_CLASSES),\n","        # )\n","        \n","        self.conv1 = conv_block(3, 64)\n","        self.conv2 = conv_block(64, 128, pool=True)\n","        self.conv3 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n","\n","        self.conv4 = conv_block(128, 256, pool=True)\n","        self.conv5 = conv_block(256, 512, pool=True)\n","        self.conv6 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n","        self.conv7 = conv_block(512, 1028, pool=True)\n","        self.conv8 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))\n","\n","        self.fc_net = nn.Sequential(nn.MaxPool2d(2), \n","                                        nn.Flatten(), \n","                                        nn.Linear(1028, TOTAL_CLASSES))\n","        \n","\n","    # def forward(self, x):\n","\n","    #     # # <<TODO#3&#4>> Based on the above edits, you'll have\n","    #     # # to edit the forward pass description here.\n","\n","    #     # x = self.pool(F.relu(self.conv1(x)))\n","    #     # # Output size = 28//2 x 28//2 = 14 x 14\n","\n","    #     # x = self.pool(F.relu(self.conv2(x)))\n","    #     # # Output size = 10//2 x 10//2 = 5 x 5\n","\n","    #     # # See the CS231 link to understand why this is 16*5*5!\n","    #     # # This will help you design your own deeper network\n","    #     # x = x.view(-1, 16 * 5 * 5)\n","    #     # x = self.fc_net(x)\n","\n","    #     # # No softmax is needed as the loss function in step 3\n","    #     # # takes care of that\n","\n","    #     # x = self.conv_net(x)\n","    #     # x = x.view(x.size(0), -1)\n","    #     # x = self.fc_net(x)\n","\n","    #     # return x\n","\n","    def forward(self, x):  \n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x) + x\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        x = self.conv6(x) + x\n","        x = self.conv7(x)\n","        x = self.conv8(x) + x\n","        x = self.fc_net(x)\n","        \n","        return x\n","\n","\n","# Create an instance of the nn.module class defined above:\n","net = BaseNet()\n","\n","# For training on GPU, we need to transfer net and data onto the GPU\n","# http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n","if IS_GPU:\n","    net = net.cuda()\n","\n","print(net)\n","from torchsummary import summary\n","from torchvision import models\n","summary(net, (3, 32, 32)) "],"metadata":{"id":"H4HHr3juyhLI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675232014322,"user_tz":480,"elapsed":7812,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"outputId":"dd6e3c8f-37f7-4e09-c35a-650faac5ba57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BaseNet(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv3): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","  )\n","  (conv4): Sequential(\n","    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv5): Sequential(\n","    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv6): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","  )\n","  (conv7): Sequential(\n","    (0): Conv2d(512, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv8): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","  )\n","  (fc_net): Sequential(\n","    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (1): Flatten(start_dim=1, end_dim=-1)\n","    (2): Linear(in_features=1028, out_features=100, bias=True)\n","  )\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","            Conv2d-4          [-1, 128, 32, 32]          73,856\n","       BatchNorm2d-5          [-1, 128, 32, 32]             256\n","              ReLU-6          [-1, 128, 32, 32]               0\n","         MaxPool2d-7          [-1, 128, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]         147,584\n","       BatchNorm2d-9          [-1, 128, 16, 16]             256\n","             ReLU-10          [-1, 128, 16, 16]               0\n","           Conv2d-11          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-12          [-1, 128, 16, 16]             256\n","             ReLU-13          [-1, 128, 16, 16]               0\n","           Conv2d-14          [-1, 256, 16, 16]         295,168\n","      BatchNorm2d-15          [-1, 256, 16, 16]             512\n","             ReLU-16          [-1, 256, 16, 16]               0\n","        MaxPool2d-17            [-1, 256, 8, 8]               0\n","           Conv2d-18            [-1, 512, 8, 8]       1,180,160\n","      BatchNorm2d-19            [-1, 512, 8, 8]           1,024\n","             ReLU-20            [-1, 512, 8, 8]               0\n","        MaxPool2d-21            [-1, 512, 4, 4]               0\n","           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n","             ReLU-24            [-1, 512, 4, 4]               0\n","           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n","             ReLU-27            [-1, 512, 4, 4]               0\n","           Conv2d-28           [-1, 1028, 4, 4]       4,738,052\n","      BatchNorm2d-29           [-1, 1028, 4, 4]           2,056\n","             ReLU-30           [-1, 1028, 4, 4]               0\n","        MaxPool2d-31           [-1, 1028, 2, 2]               0\n","           Conv2d-32           [-1, 1028, 2, 2]       9,512,084\n","      BatchNorm2d-33           [-1, 1028, 2, 2]           2,056\n","             ReLU-34           [-1, 1028, 2, 2]               0\n","           Conv2d-35           [-1, 1028, 2, 2]       9,512,084\n","      BatchNorm2d-36           [-1, 1028, 2, 2]           2,056\n","             ReLU-37           [-1, 1028, 2, 2]               0\n","        MaxPool2d-38           [-1, 1028, 1, 1]               0\n","          Flatten-39                 [-1, 1028]               0\n","           Linear-40                  [-1, 100]         102,900\n","================================================================\n","Total params: 30,441,528\n","Trainable params: 30,441,528\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 9.68\n","Params size (MB): 116.13\n","Estimated Total Size (MB): 125.81\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","metadata":{"id":"5b_fBznndp4W"},"source":["# '''\n","# ########################################################################\n","# # 2. Define a Convolution Neural Network\n","# # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","# # We provide a basic network that you should understand, run and\n","# # eventually improve\n","# # <<TODO>> Add more conv layers\n","# # <<TODO>> Add more fully connected (fc) layers\n","# # <<TODO>> Add regularization layers like Batchnorm.\n","# #          nn.BatchNorm2d after conv layers:\n","# #          http://pytorch.org/docs/master/nn.html#batchnorm2d\n","# #          nn.BatchNorm1d after fc layers:\n","# #          http://pytorch.org/docs/master/nn.html#batchnorm1d\n","# # This is a good resource for developing a CNN for classification:\n","# # http://cs231n.github.io/convolutional-networks/#layers\n","\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","\n","# class BaseNet(nn.Module):\n","#     def __init__(self):\n","#         super(BaseNet, self).__init__()\n","        \n","#         # <<TODO#3>> Add more conv layers with increasing \n","#         # output channels\n","#         # <<TODO#4>> Add normalization layers after conv\n","#         # layers (nn.BatchNorm2d)\n","\n","#         # Also experiment with kernel size in conv2d layers (say 3\n","#         # inspired from VGGNet)\n","#         # To keep it simple, keep the same kernel size\n","#         # (right now set to 5) in all conv layers.\n","#         # Do not have a maxpool layer after every conv layer in your\n","#         # deeper network as it leads to too much loss of information.\n","\n","#         self.conv1 = nn.Conv2d(3, 6, 5) #in-channel, out-channel, kernel size\n","#         self.norm1 = nn.BatchNorm2d(6)\n","\n","#         self.conv2 = nn.Conv2d(6, 16, 5)\n","#         self.norm2 = nn.BatchNorm2d(16)\n","\n","#         self.pool = nn.MaxPool2d(2, 2) #added - UA\n","\n","#         self.conv3 = nn.Conv2d(9, 24, 3)\n","#         self.norm3 = nn.BatchNorm2d(24)\n","\n","#         self.conv4 = nn.Conv2d(12, 36, 3)\n","#         self.norm4 = nn.BatchNorm2d(36)\n","\n","#         self.pool = nn.MaxPool2d(2, 2)\n","\n","#         # <<TODO#3>> Add more linear (fc) layers\n","#         # <<TODO#4>> Add normalization layers after linear and\n","#         # experiment inserting them before or after ReLU (nn.BatchNorm1d)\n","#         # More on nn.sequential:\n","#         # http://pytorch.org/docs/master/nn.html#torch.nn.Sequential\n","        \n","#         self.fc_net = nn.Sequential(\n","#             nn.Linear(16 * 5 * 5, TOTAL_CLASSES//2),\n","#             nn.ReLU(inplace=True),\n","#             nn.Linear(TOTAL_CLASSES//2, TOTAL_CLASSES),\n","#         )\n","\n","#     def forward(self, x):\n","\n","#         # <<TODO#3&#4>> Based on the above edits, you'll have\n","#         # to edit the forward pass description here.\n","\n","#         x = self.pool(F.relu(self.conv1(x)))\n","#         # Output size = 28//2 x 28//2 = 14 x 14\n","\n","#         x = self.pool(F.relu(self.conv2(x)))\n","#         # Output size = 10//2 x 10//2 = 5 x 5\n","\n","#         # See the CS231 link to understand why this is 16*5*5!\n","#         # This will help you design your own deeper network\n","#         x = x.view(-1, 16 * 5 * 5)\n","#         x = self.fc_net(x)\n","\n","#         # No softmax is needed as the loss function in step 3\n","#         # takes care of that\n","        \n","#         return x\n","\n","# # Create an instance of the nn.module class defined above:\n","# net = BaseNet()\n","\n","# # For training on GPU, we need to transfer net and data onto the GPU\n","# # http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n","# if IS_GPU:\n","#     net = net.cuda()\n","# '''\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zAZjIcLOdp-W"},"source":["########################################################################\n","# 3. Define a Loss function and optimizer\n","# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","# Here we use Cross-Entropy loss and SGD with momentum.\n","# The CrossEntropyLoss criterion already includes softmax within its\n","# implementation. That's why we don't use a softmax in our model\n","# definition.\n","\n","import torch.optim as optim\n","criterion = nn.CrossEntropyLoss()\n","\n","# Tune the learning rate.\n","# See whether the momentum is useful or not\n","optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n","#lr=0.005\n","plt.ioff()\n","fig = plt.figure()\n","train_loss_over_epochs = []\n","val_accuracy_over_epochs = []\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ku7eF366dyUP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"78483015-ef45-4111-888c-9a800c852b61","executionInfo":{"status":"ok","timestamp":1675233505623,"user_tz":480,"elapsed":1491311,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}}},"source":["########################################################################\n","# 4. Train the network\n","# ^^^^^^^^^^^^^^^^^^^^\n","#\n","# We simply have to loop over our data iterator, and feed the inputs to the\n","# network and optimize. We evaluate the validation accuracy at each\n","# epoch and plot these values over the number of epochs\n","# Nothing to change here\n","# -----------------------------\n","for epoch in range(EPOCHS):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        if IS_GPU:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","\n","        # wrap them in Variable\n","        inputs, labels = Variable(inputs), Variable(labels)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    \n","    # Normalizing the loss by the total number of train batches\n","    running_loss/=len(trainloader)\n","    print('[%d] loss: %.3f' %\n","          (epoch + 1, running_loss))\n","\n","    # Scale of 0.0 to 100.0\n","    # Calculate validation set accuracy of the existing model\n","    val_accuracy, val_classwise_accuracy = \\\n","        calculate_val_accuracy(valloader, IS_GPU)\n","    print('Accuracy of the network on the val images: %d %%' % (val_accuracy))\n","\n","    # # Optionally print classwise accuracies\n","    # for c_i in range(TOTAL_CLASSES):\n","    #     print('Accuracy of %5s : %2d %%' % (\n","    #         classes[c_i], 100 * val_classwise_accuracy[c_i]))\n","\n","    train_loss_over_epochs.append(running_loss)\n","    val_accuracy_over_epochs.append(val_accuracy)\n","# -----------------------------\n","\n","\n","# Plot train loss over epochs and val set accuracy over epochs\n","# Nothing to change here\n","# -------------\n","plt.subplot(2, 1, 1)\n","plt.ylabel('Train loss')\n","plt.plot(np.arange(EPOCHS), train_loss_over_epochs, 'k-')\n","plt.title('train loss and val accuracy')\n","plt.xticks(np.arange(EPOCHS, dtype=int))\n","plt.grid(True)\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(np.arange(EPOCHS), val_accuracy_over_epochs, 'b-')\n","plt.ylabel('Val accuracy')\n","plt.xlabel('Epochs')\n","plt.xticks(np.arange(EPOCHS, dtype=int))\n","plt.grid(True)\n","plt.savefig(\"plot.png\")\n","plt.close(fig)\n","print('Finished Training')\n","# -------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1] loss: 4.524\n","Accuracy of the network on the val images: 15 %\n","[2] loss: 3.409\n","Accuracy of the network on the val images: 28 %\n","[3] loss: 2.772\n","Accuracy of the network on the val images: 38 %\n","[4] loss: 2.348\n","Accuracy of the network on the val images: 44 %\n","[5] loss: 2.047\n","Accuracy of the network on the val images: 50 %\n","[6] loss: 1.816\n","Accuracy of the network on the val images: 53 %\n","[7] loss: 1.636\n","Accuracy of the network on the val images: 56 %\n","[8] loss: 1.483\n","Accuracy of the network on the val images: 57 %\n","[9] loss: 1.360\n","Accuracy of the network on the val images: 60 %\n","[10] loss: 1.248\n","Accuracy of the network on the val images: 60 %\n","[11] loss: 1.163\n","Accuracy of the network on the val images: 63 %\n","[12] loss: 1.082\n","Accuracy of the network on the val images: 63 %\n","[13] loss: 0.997\n","Accuracy of the network on the val images: 65 %\n","[14] loss: 0.909\n","Accuracy of the network on the val images: 65 %\n","[15] loss: 0.852\n","Accuracy of the network on the val images: 65 %\n","[16] loss: 0.781\n","Accuracy of the network on the val images: 66 %\n","[17] loss: 0.729\n","Accuracy of the network on the val images: 66 %\n","[18] loss: 0.672\n","Accuracy of the network on the val images: 67 %\n","[19] loss: 0.614\n","Accuracy of the network on the val images: 66 %\n","[20] loss: 0.565\n","Accuracy of the network on the val images: 67 %\n","[21] loss: 0.526\n","Accuracy of the network on the val images: 68 %\n","[22] loss: 0.481\n","Accuracy of the network on the val images: 67 %\n","[23] loss: 0.431\n","Accuracy of the network on the val images: 68 %\n","[24] loss: 0.399\n","Accuracy of the network on the val images: 67 %\n","[25] loss: 0.375\n","Accuracy of the network on the val images: 68 %\n","Finished Training\n"]}]},{"cell_type":"code","metadata":{"id":"v1GE8t3mRdy9"},"source":["########################################################################\n","# 5. Try the network on test data, and create .csv file\n","# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","########################################################################\n","\n","# Check out why .eval() is important!\n","# https://discuss.pytorch.org/t/model-train-and-model-eval-vs-model-and-model-eval/5744/2\n","net.eval()\n","\n","total = 0\n","predictions = []\n","for data in testloader:\n","    images, labels = data\n","\n","    # For training on GPU, we need to transfer net and data onto the GPU\n","    # http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n","    if IS_GPU:\n","        images = images.cuda()\n","        labels = labels.cuda()\n","    \n","    outputs = net(Variable(images))\n","    _, predicted = torch.max(outputs.data, 1)\n","    predictions.extend(list(predicted.cpu().numpy()))\n","    total += labels.size(0)\n","\n","with open('submission_netid.csv', 'w') as csvfile:\n","    wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n","    wr.writerow([\"Id\", \"Prediction1\"])\n","    for l_i, label in enumerate(predictions):\n","        wr.writerow([str(l_i), str(label)])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"og2F2MLhs7L6"},"source":["# Part 2"]},{"cell_type":"code","metadata":{"id":"prD0eXGpdoCR","executionInfo":{"status":"ok","timestamp":1675235779015,"user_tz":480,"elapsed":20191,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}}},"source":["\"\"\"Headers\"\"\"\n","import os\n","import os.path as osp\n","import time\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torch.optim as optim\n","\n","from torchvision import datasets"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P6CJz7OM0J9Z"},"source":["# Pre-Trained Model\n","\n","TODO1. Load pretrained resnet model. Experiment with different models. \n","\n","TODO2: Replace last fc layer\n","\n","TODO3. Forward pass"]},{"cell_type":"code","metadata":{"id":"HUdo6AkH0maX","executionInfo":{"status":"ok","timestamp":1675235782520,"user_tz":480,"elapsed":235,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}}},"source":["class PreTrainedResNet(nn.Module):\n","  def __init__(self, num_classes, feature_extracting):\n","    super(PreTrainedResNet, self).__init__()\n","    \n","    #TODO1: Load pre-trained ResNet Model\n","    self.resnet18 = models.resnet18(pretrained = True)\n","\n","    #Set gradients to false\n","    if feature_extracting:\n","      for param in self.resnet18.parameters():\n","          param.requires_grad = False\n","    \n","    #Replace last fc layer\n","    num_feats = self.resnet18.fc.in_features\n","    \n","    #TODO2: Replace fc layer in resnet to a linear layer of size (num_feats, num_classes)\n","    self.resnet18.fc = nn.Linear(num_feats, num_classes)\n","    \n","  def forward(self, x):\n","    #TODO3: Forward pass x through the model\n","    x = self.resnet18.forward(x)\n","    return x"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_DRbNt8Jask"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"ujUNEVsEvWwv","executionInfo":{"status":"ok","timestamp":1675235785006,"user_tz":480,"elapsed":2,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}}},"source":["def train(model, optimizer, criterion, epoch, num_epochs):\n","  model.train()\n","  epoch_loss = 0.0\n","  epoch_acc = 0.0\n","  \n","  for batch_idx, (images, labels) in enumerate(dataloaders['train']):\n","    #zero the parameter gradients\n","    optimizer.zero_grad()\n","    \n","    #move to GPU\n","    images, labels = images.cuda(), labels.cuda()\n","    \n","    #forward\n","    outputs = model.forward(images)\n","    \n","    loss = criterion(outputs, labels)\n","    \n","    _, preds = torch.max(outputs.data, 1)\n","    \n","    loss.backward()\n","    optimizer.step()\n","    \n","    epoch_loss += loss.item()\n","    epoch_acc += torch.sum(preds == labels).item()\n","    \n","  epoch_loss /= dataset_sizes['train']\n","  epoch_acc /= dataset_sizes['train']\n","  \n","  print('TRAINING Epoch %d/%d Loss %.4f Accuracy %.4f' % (epoch, num_epochs, epoch_loss, epoch_acc))"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mAbNgE4r7vm-"},"source":["# Main\n","\n","1. Vary hyperparams\n","2. Data augmentation"]},{"cell_type":"code","metadata":{"id":"oZkI3scVWjOQ","executionInfo":{"status":"error","timestamp":1675238184154,"user_tz":480,"elapsed":362380,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"colab":{"base_uri":"https://localhost:8080/","height":818},"outputId":"a44fb9f8-dbfa-4940-bf5e-c37deac966ee"},"source":["#TODO: Vary Hyperparams\n","\n","NUM_EPOCHS = 25\n","LEARNING_RATE = 0.001 \n","BATCH_SIZE = 8\n","RESNET_LAST_ONLY = False #Fine tunes only the last layer. Set to False to fine tune entire network\n","\n","root_path = '/data/' #If your data is in a different folder, set the path accodordingly\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize(256),\n","        #TODO: Transforms.RandomResizedCrop() instead of CenterCrop(), RandomRoate() and Horizontal Flip()\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        #TODO: Transforms.Normalize()\n","        transforms.Normalize(mean = [0.5,0.5,0.5], std = [0.5,0.5,0.5])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        #TODO: Transforms.Normalize()\n","        transforms.Normalize(mean = [0.5,0.5,0.5], std = [0.5,0.5,0.5])\n","    ]),\n","}\n","\n","# loading datasets with PyTorch ImageFolder\n","image_datasets = {x: datasets.ImageFolder(os.path.join(root_path, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'test']}\n","\n","# defining data loaders to load data using image_datasets and transforms, here we also specify batch size for the mini batch\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE,\n","                                             shuffle=True, num_workers=4)\n","              for x in ['train', 'test']}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n","class_names = image_datasets['train'].classes\n","\n","#Initialize the model\n","model = PreTrainedResNet(len(class_names), RESNET_LAST_ONLY)\n","model = model.cuda()\n","\n","#Setting the optimizer and loss criterion\n","optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","criterion = nn.CrossEntropyLoss()\n","\n","#Begin Train\n","for epoch in range(NUM_EPOCHS):\n","  train(model, optimizer, criterion, epoch+1, NUM_EPOCHS)\n","  \n","print(\"Finished Training\")\n","print(\"-\"*10)"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING Epoch 1/25 Loss 0.6590 Accuracy 0.0167\n","TRAINING Epoch 2/25 Loss 0.5951 Accuracy 0.0657\n","TRAINING Epoch 3/25 Loss 0.5392 Accuracy 0.1527\n","TRAINING Epoch 4/25 Loss 0.4936 Accuracy 0.2227\n","TRAINING Epoch 5/25 Loss 0.4608 Accuracy 0.2760\n","TRAINING Epoch 6/25 Loss 0.4245 Accuracy 0.3407\n","TRAINING Epoch 7/25 Loss 0.3999 Accuracy 0.3870\n","TRAINING Epoch 8/25 Loss 0.3753 Accuracy 0.4190\n","TRAINING Epoch 9/25 Loss 0.3606 Accuracy 0.4343\n","TRAINING Epoch 10/25 Loss 0.3425 Accuracy 0.4607\n","TRAINING Epoch 11/25 Loss 0.3227 Accuracy 0.4920\n","TRAINING Epoch 12/25 Loss 0.3193 Accuracy 0.5010\n","TRAINING Epoch 13/25 Loss 0.2995 Accuracy 0.5243\n","TRAINING Epoch 14/25 Loss 0.2924 Accuracy 0.5380\n","TRAINING Epoch 15/25 Loss 0.2821 Accuracy 0.5440\n","TRAINING Epoch 16/25 Loss 0.2746 Accuracy 0.5660\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-accd196f0182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#Begin Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-e433cdffc4b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, epoch, num_epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"DEbsnh3a7ljw"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"4wyYKmQ91woU","executionInfo":{"status":"ok","timestamp":1675236617728,"user_tz":480,"elapsed":244,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}}},"source":["def test(model, criterion, repeats=2):\n","  model.eval()\n","  \n","  test_loss = 0.0\n","  test_acc = 0.0\n","  \n","  with torch.no_grad():\n","    for itr in range(repeats):\n","      for batch_idx, (images, labels) in enumerate(dataloaders['test']):\n","        #move to GPU\n","        images, labels = images.cuda(), labels.cuda()\n","\n","        #forward\n","        outputs = model.forward(images)\n","\n","        loss = criterion(outputs, labels)\n","\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        test_loss += loss.item()\n","        test_acc += torch.sum(preds == labels).item()\n","\n","    test_loss /= (dataset_sizes['test']*repeats)\n","    test_acc /= (dataset_sizes['test']*repeats)\n","\n","    print('Test Loss: %.4f Test Accuracy %.4f' % (test_loss, test_acc))\n"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"znXWR6oWyl-B","executionInfo":{"status":"ok","timestamp":1675236654418,"user_tz":480,"elapsed":32545,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"af747349-8884-4c85-97a4-d3d1c61a23b1"},"source":["test(model, criterion)"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.2137 Test Accuracy 0.5753\n"]}]},{"cell_type":"markdown","metadata":{"id":"kNX2g3AYUbM2"},"source":["# Visualizing the model predictions\n","\n","Only for viusalizing. Nothing to be done here. "]},{"cell_type":"code","metadata":{"id":"Zd_lkTdoUaOX"},"source":["def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(1)  # pause a bit so that plots are updated\n","    \n","def visualize_model(model, num_images=8):\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    for batch_idx, (images, labels) in enumerate(dataloaders['test']):\n","        #move to GPU\n","        images, labels = images.cuda(), labels.cuda()\n","        \n","        outputs = model(images)\n","        \n","        _, preds = torch.max(outputs.data, 1)\n","       \n","\n","        for j in range(images.size()[0]):\n","            images_so_far += 1\n","            ax = plt.subplot(num_images//2, 2, images_so_far)\n","            ax.axis('off')\n","            ax.set_title('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n","\n","            imshow(images.cpu().data[j])\n","\n","            if images_so_far == num_images:\n","                return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sxjSnLKOJsTW","executionInfo":{"status":"error","timestamp":1675237812394,"user_tz":480,"elapsed":4891,"user":{"displayName":"Utsav Anantbhat","userId":"01205210428009884154"}},"colab":{"base_uri":"https://localhost:8080/","height":631},"outputId":"914068ee-f798-4efd-cfa8-7b2ec1e912a4"},"source":["visualize_model(model)"],"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-8356e88ead70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-38-9515e2f00dcb>\u001b[0m in \u001b[0;36mvisualize_model\u001b[0;34m(model, num_images)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class: {} predicted: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimages_so_far\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-38-9515e2f00dcb>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(inp, title)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pause a bit so that plots are updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mstart_event_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2308\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_looping\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}